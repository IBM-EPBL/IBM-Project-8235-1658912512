{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "kOY8VqknmsMk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mwj4VIk4mpJV"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from skimage import feature\n",
        "from imutils import build_montages\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pickle "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantifiying Images"
      ],
      "metadata": {
        "id": "JV88iwNpm4JB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantify_image(image):\n",
        "\t# compute the histogram of oriented gradients feature vector for\n",
        "\t# the input image\n",
        "\tfeatures = feature.hog(image, orientations=9,\n",
        "\t\tpixels_per_cell=(10, 10), cells_per_block=(2, 2),\n",
        "\t\ttransform_sqrt=True, block_norm=\"L1\")\n",
        "\n",
        "\t# return the feature vector\n",
        "\treturn features\n"
      ],
      "metadata": {
        "id": "CQRIrxDXm3qB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Train Split"
      ],
      "metadata": {
        "id": "T34RgFrjnClq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_split(path):\n",
        "\t# grab the list of images in the input directory, then initialize\n",
        "\t# the list of data (i.e., images) and class labels\n",
        "\timagePaths = list(paths.list_images(path))\n",
        "\tdata = []\n",
        "\tlabels = []\n",
        "\n",
        "\t# loop over the image paths\n",
        "\tfor imagePath in imagePaths:\n",
        "\t\t# extract the class label from the filename\n",
        "\t\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t\t# load the input image, convert it to grayscale, and resize\n",
        "\t\t# it to 200x200 pixels, ignoring aspect ratio\n",
        "\t\timage = cv2.imread(imagePath)\n",
        "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\t\timage = cv2.resize(image, (200, 200))\n",
        "\n",
        "\t\t# threshold the image such that the drawing appears as white\n",
        "\t\t# on a black background\n",
        "\t\timage = cv2.threshold(image, 0, 255,\n",
        "\t\t\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "\t\t# quantify the image\n",
        "\t\tfeatures = quantify_image(image)\n",
        "\n",
        "\t\t# update the data and labels lists, respectively\n",
        "\t\tdata.append(features)\n",
        "\t\tlabels.append(label)\n",
        "\n",
        "\t# return the data and labels\n",
        "\treturn (np.array(data), np.array(labels))\n",
        "trainingPath = r\"/content/drive/MyDrive/Dataset/spiral/training\"\n",
        "testingPath = r\"/content/drive/MyDrive/Dataset/spiral/testing\"\n",
        "\n",
        "# loading the training and testing data\n",
        "print(\"[INFO] loading data...\")\n",
        "(X_train, y_train) = load_split(trainingPath)\n",
        "(X_test, y_test) = load_split(testingPath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G94cRh_2nFF3",
        "outputId": "d6118dd2-5d93-41b1-c4dd-bb47e90e9079"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoding"
      ],
      "metadata": {
        "id": "7V61M3TanaMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(\"[INFO] training model\")\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model,open('parkinson.pkl','wb')) \n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FynjpDeenUT2",
        "outputId": "e07c918e-272b-412e-cac7-7eeee274a425"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 12996) (72,)\n",
            "[INFO] training model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "HnZ9jU4Ynq7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, predictions).flatten()\n",
        "print(cm)\n",
        "(tn, fp, fn, tp) = cm\n",
        "accuracy = (tp + tn) / float(cm.sum())\n",
        "print(accuracy)\n",
        "\n",
        "# randomly select a few images and then initialize the output images\n",
        "# for the montage\n",
        "testingPaths = list(paths.list_images(testingPath))\n",
        "idxs = np.arange(0, len(testingPaths))\n",
        "idxs = np.random.choice(idxs, size=(25,), replace=False)\n",
        "images = []\n",
        "\n",
        "# loop over the testing samples\n",
        "for i in idxs:\n",
        "\t# load the testing image, clone it, and resize it\n",
        "\timage = cv2.imread(testingPaths[i])\n",
        "\toutput = image.copy()\n",
        "\toutput = cv2.resize(output, (128, 128))\n",
        "\n",
        "\t# pre-process the image in the same manner we did earlier\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\timage = cv2.resize(image, (200, 200))\n",
        "\timage = cv2.threshold(image, 0, 255,\n",
        "\t\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "\t# quantify the image and make predictions based on the extracted\n",
        "\t# features using the last trained Random Forest\n",
        "\tfeatures = quantify_image(image)\n",
        "\tpreds = model.predict([features])\n",
        "    \n",
        "\tlabel = le.inverse_transform(preds)[0]\n",
        "\n",
        "\t# draw the colored class label on the output image and add it to\n",
        "\t# the set of output images\n",
        "\tcolor = (0, 255, 0) if label == \"healthy\" else (0, 0, 255)\n",
        "\tcv2.putText(output, label, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "\t\tcolor, 2)\n",
        "\timages.append(output)\n",
        "\n",
        "# create a montage using 128x128 \"tiles\" with 5 rows and 5 columns\n",
        "montage = build_montages(images, (128, 128), (5, 5))[0]\n",
        "\n",
        "# show the output montage\n",
        "# cv2.imshow(\"Output\", montage)\n",
        "# cv2.waitKey(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQbYzSxonvUw",
        "outputId": "b9d18e73-4492-49eb-de5a-b830a0a873e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14  1  4 11]\n",
            "0.8333333333333334\n"
          ]
        }
      ]
    }
  ]
}